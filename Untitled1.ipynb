{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bb2d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "008517ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Product</th>\n",
       "      <th>Tank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>['A3', 'D3', 'M3']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>['54', '56', '62']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>['54', '62', '96']</td>\n",
       "      <td>[310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>['54', '62', '96']</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>['54', '62', '96']</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2A</td>\n",
       "      <td>['62']</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2A</td>\n",
       "      <td>['62']</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2A</td>\n",
       "      <td>['62']</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2A</td>\n",
       "      <td>['62']</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2A</td>\n",
       "      <td>['62']</td>\n",
       "      <td>376]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line             Product  Tank\n",
       "0    01  ['A3', 'D3', 'M3']   NaN\n",
       "1    02  ['54', '56', '62']   NaN\n",
       "2    13  ['54', '62', '96']  [310\n",
       "2    13  ['54', '62', '96']   311\n",
       "2    13  ['54', '62', '96']   312\n",
       "..  ...                 ...   ...\n",
       "11   2A              ['62']   371\n",
       "11   2A              ['62']   373\n",
       "11   2A              ['62']   374\n",
       "11   2A              ['62']   375\n",
       "11   2A              ['62']  376]\n",
       "\n",
       "[207 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lines.explode('Tank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e78766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Line       Product                                           Tank\n",
      "0    13  [54, 62, 96]  [310, 311, 312, 313, 314, 316, 317, 330, 331]\n",
      "\n",
      "Exploded DataFrame:\n",
      "   Line       Product Tank\n",
      "0    13  [54, 62, 96]  310\n",
      "0    13  [54, 62, 96]  311\n",
      "0    13  [54, 62, 96]  312\n",
      "0    13  [54, 62, 96]  313\n",
      "0    13  [54, 62, 96]  314\n",
      "0    13  [54, 62, 96]  316\n",
      "0    13  [54, 62, 96]  317\n",
      "0    13  [54, 62, 96]  330\n",
      "0    13  [54, 62, 96]  331\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'Line': [13],\n",
    "    'Product': [['54', '62', '96']],\n",
    "    'Tank': [[310, 311, 312, 313, 314, 316, 317, 330, 331]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Explode the 'Tank' column\n",
    "df_exploded = df.explode('Tank')\n",
    "\n",
    "# Display the exploded DataFrame\n",
    "print(\"\\nExploded DataFrame:\")\n",
    "print(df_exploded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "514d601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{310: {'01': {'M4': 0}}, 311: {'01': {'A3': 0}}, 312: {'01': {'D4': 0}}, 313: {'01': {'A2': 0}}, 314: {'01': {'A3': 0}}, 315: {'01': {'V4': 0}}, 316: {'01': {'A2': 0}}, 317: {'01': {'D3': 0}}, 330: {'01': {'A3': 0}}, 331: {}, 332: {'01': {'A3': 0}}, 333: {}, 334: {'01': {'A3': 0}}, 335: {'01': {'A3': 0}}, 336: {'01': {'A3': 0}}, 337: {'01': {'A5': 0}}, 338: {'01': {'A3': 0}}, 339: {'01': {'A3': 0}}, 350: {'02': {'54': 0}}, 351: {}, 352: {'02': {'54': 0}}, 353: {'02': {'54': 0}}, 354: {'02': {'54': 0}}, 360: {'02': {'62': 0}}, 361: {'02': {'62': 0}}, 363: {'02': {'51': 0}}, 370: {'02': {'54': 0}}, 371: {}, 372: {'02': {'96': 0}}, 373: {'02': {'62': 0}}, 374: {'02': {'62': 0}}, 375: {'02': {'62': 0}}, 376: {'02': {'62': 0}}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # Import abstract syntax trees to safely evaluate strings as Python expressions\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = 'input_location/dim_tanks.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'Lineout' from string to list\n",
    "df['Lineout'] = df['LineOut'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "df['Linein'] = df['LineIn'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "tank_dict = {}\n",
    "\n",
    "# Iterate through each row to populate the dictionary\n",
    "b = {}\n",
    "for index, row in df.iterrows():\n",
    "    tank = row['Tank']\n",
    "    product = row['Product']\n",
    "    lines = row['Linein']  # Assuming this is already a list, convert if it's a string\n",
    "\n",
    "    a = {}\n",
    "    if pd.notna(product):  # Check if product is not NaN before entering the loop\n",
    "        for line in lines:\n",
    "            line = str(line).zfill(2)\n",
    "            a[line] = {product: 0}\n",
    "    b[tank] = a  \n",
    "    \n",
    "\n",
    "# Output the resulting dictionary\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "338c81aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['Low Level', 'Normal Fill', 'Max Capacity', 'Type', 'Out of Service']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grouped\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLine\u001b[39m\u001b[38;5;124m'\u001b[39m: line_column_name})\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Read only the necessary columns from the main tank file\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_file, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     17\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOut of Service\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow Level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal Fill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Capacity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Rename the column\u001b[39;00m\n\u001b[0;32m     21\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow Level\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBottom\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal Fill\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWorking\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Capacity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:140\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(usecols)\u001b[38;5;241m.\u001b[39missubset(\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names\n\u001b[0;32m    139\u001b[0m ):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(usecols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(usecols):  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:959\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[1;34m(self, usecols, names)\u001b[0m\n\u001b[0;32m    957\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m usecols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    961\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usecols\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['Low Level', 'Normal Fill', 'Max Capacity', 'Type', 'Out of Service']"
     ]
    }
   ],
   "source": [
    "base_input_path = Path('input_cycle/v2')\n",
    "base_output_path = Path('input_location')\n",
    "input_file = base_input_path / 'tankInventory.csv'\n",
    "output_file = base_output_path / 'dim_tanks.csv'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "base_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Function to read and group lines by tank\n",
    "def group_lines(file_path, line_column_name):\n",
    "    df_lines = pd.read_csv(file_path, usecols=['Tank', 'Line'])\n",
    "    grouped = df_lines.groupby('Tank')['Line'].agg(list).reset_index()\n",
    "    return grouped.rename(columns={'Line': line_column_name})\n",
    "\n",
    "# Read only the necessary columns from the main tank file\n",
    "df = pd.read_csv(input_file, usecols=['Tank', 'Type', 'Product', \n",
    "                                      'Type', 'Out of Service',\n",
    "                                      'Low Level', 'Normal Fill', 'Max Capacity'])\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={'Low Level': 'Bottom',\n",
    "                  'Normal Fill': 'Working',\n",
    "                  'Max Capacity': 'Maximum'}, inplace=True)\n",
    "\n",
    "# Columns to modify\n",
    "columns_to_modify = ['Bottom', 'Working', 'Maximum']\n",
    "\n",
    "# Divide by 100 and round to three decimal places\n",
    "df[columns_to_modify] = df[columns_to_modify].div(1000).round(0)\n",
    "\n",
    "\n",
    "# Process and merge line out data\n",
    "line_out_path = base_output_path / 'topoO_ATJ.csv'\n",
    "line_out_data = group_lines(line_out_path, 'LineOut')\n",
    "df = df.merge(line_out_data, on='Tank', how='left')\n",
    "\n",
    "# Process and merge line in data\n",
    "line_in_path = base_output_path / 'topoI_ATJ.csv'\n",
    "line_in_data = group_lines(line_in_path, 'LineIn')\n",
    "df = df.merge(line_in_data, on='Tank', how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
